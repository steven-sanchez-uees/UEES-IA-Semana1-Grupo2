# Actividad 1: Laboratorio PrÃ¡ctico en Google Colab

## Estructura del Proyecto

```
â”œâ”€â”€ 01_Fundamentos_NumPy_Pandas
â”‚   â”œâ”€â”€ 01_Fundamentos_NumPy_Pandas.ipynb
â”‚   â””â”€â”€ images
â”‚       â””â”€â”€ 01_iris_petal_ratio.png
â”‚
â”œâ”€â”€ 02_Visualizacion_Datos
â”‚   â”œâ”€â”€ 02_Visualizacion_Datos.ipynb
â”‚   â””â”€â”€ images
â”‚       â”œâ”€â”€ 02_titanic_genero.png
â”‚       â”œâ”€â”€ 02_titanic_edad_clase.png
â”‚       â””â”€â”€ 02_wine_plot_interactivo.html
â”‚
â”œâ”€â”€ 03_Machine_Learning_Basico
â”‚   â”œâ”€â”€ 03_Machine_Learning_Basico.ipynb
â”‚   â””â”€â”€ images
â”‚       â”œâ”€â”€ accuracy_comparison.png
â”‚       â”œâ”€â”€ confusion_matrix_decision_tree.png
â”‚       â”œâ”€â”€ confusion_matrix_logistic_regression.png
â”‚       â”œâ”€â”€ confusion_matrix_random_forest.png
â”‚       â”œâ”€â”€ model_comparison.png
â”‚       â””â”€â”€ proba_distribution.png
â”‚
â”œâ”€â”€ 04_Deep_Learning_Intro
â”‚   â”œâ”€â”€ 04_Deep_Learning_Intro.ipynb
â”‚       â”œâ”€â”€ accuracy_plot.png
â”‚       â”œâ”€â”€ confusion_matrix.png
â”‚       â”œâ”€â”€ loss_plot.png
â”‚       â””â”€â”€ predicciones_random.png
â”‚
â””â”€â”€ README.md
â”‚
â””â”€â”€ requirements.txt
```

## Informe Ejecutivo

### 1. Fundamentos NumPy y Pandas
En el anÃ¡lisis se identificaron diferencias claras entre tipos de flores al comparar la proporciÃ³n entre el largo y ancho de sus pÃ©talos; Esta mÃ©trica permitiÃ³ visualizar patrones que podrÃ­an ser Ãºtiles para clasificarlas automÃ¡ticamente.

- Se trabajÃ³ con el dataset **Iris**.
- Se analizaron y manipularon datos utilizando arrays y DataFrames.
- Se creÃ³ una nueva mÃ©trica "petal_ratio" que permitiÃ³ observar diferencias entre especies de flores.

### AnÃ¡lisis de resultados

i. **Resumen estadÃ­stico por especie**:
   - La especie **virginica** tiene el mayor promedio de Â´petal_ratioÂ´, seguido de **versicolor** y finalmente **setosa**.
   - Esto indica que el largo del pÃ©talo de *virginica* es desproporcionadamente mayor respecto a su ancho en comparaciÃ³n con las otras especies.
   - Esta diferencia puede ser utilizada como una variable discriminante para clasificaciÃ³n automÃ¡tica.

ii. **Nueva columna petal_ratio**:
   - Se incorporÃ³ exitosamente como una nueva variable en el DataFrame.
   - La inspecciÃ³n inicial (.head()) muestra variabilidad en los valores, que serÃ¡ Ãºtil para anÃ¡lisis posterior.

iii. **DistribuciÃ³n visual**:
   - El histograma muestra que la mayorÃ­a de los valores de **petal_ratio** se concentran entre 2 y 6.
   - Hay picos notables alrededor de los valores 2.5 y 4, lo que probablemente corresponde a la especie *setosa*.
   - Las colas hacia la derecha muestran la presencia de valores altos asociados a *virginica*, confirmando su mayor razÃ³n pÃ©talo.

### Evidencias

- [Notebook 1](./01_Fundamentos_NumPy_Pandas/01_Fundamentos_NumPy_Pandas.ipynb)
- <img src="./01_Fundamentos_NumPy_Pandas/images/01_iris_petal_ratio.png" alt="01_iris_petal_ratio" width="300"/>

### ConclusiÃ³n

La mÃ©trica petal_ratio resulta ser un indicador relevante para distinguir entre especies de Iris. Su distribuciÃ³n evidencia diferencias significativas en la morfologÃ­a floral, siendo Ãºtil como variable de entrada para modelos de clasificaciÃ³n. La visualizaciÃ³n complementa este hallazgo, mostrando patrones claros entre grupos.

---


### 2. VisualizaciÃ³n de Datos
Se identificaron patrones clave que ayudan a comprender mejor los datos:

- En el caso del Titanic, los grÃ¡ficos revelaron que la edad y el gÃ©nero influyeron significativamente en la distribuciÃ³n de los pasajeros por clase. Los adultos predominaban en primera clase, mientras que en tercera clase habÃ­a mayor presencia de hombres y jÃ³venes. Esto sugiere desigualdad en el acceso a recursos dentro del barco.

- Para los vinos, el anÃ¡lisis visual mostrÃ³ que, al comparar niveles de alcohol y acidez, se formaban agrupaciones por tipo de vino. Estas diferencias quÃ­micas se pueden aprovechar para clasificarlos automÃ¡ticamente.

Se utilizaron herramientas grÃ¡ficas estÃ¡ticas y dinÃ¡micas para facilitar el anÃ¡lisis, permitiendo identificar patrones que no serÃ­an visibles solo con tablas numÃ©ricas.

### Evidencias

- [Notebook 2](./02_Visualizacion_Datos/02_Visualizacion_Datos.ipynb)
- <img src="./02_Visualizacion_Datos/images/02_titanic_edad_clase.png" alt="02_titanic_edad_clase.png" width="300"/>
- <img src="./02_Visualizacion_Datos/images/02_titanic_genero.png" alt="02_titanic_genero.png" width="300"/>
- [Ver grÃ¡fico interactivo Wine](https://steven-sanchez-uees.github.io/UEES-IA-Semana1-Grupo2/02_Visualizacion_Datos/images/02_wine_plot_interactivo.html)

### ConclusiÃ³n

La visualizaciÃ³n no solo hizo mÃ¡s comprensible la informaciÃ³n, sino que expuso relaciones ocultas entre variables que pueden apoyar decisiones y automatizar procesos como segmentaciÃ³n o clasificaciÃ³n.

---

### 3. Machine Learning Basico
En esta actividad aplicamos tÃ©cnicas de Machine Learning supervisado para resolver un problema clÃ¡sico: predecir si una persona sobreviviÃ³ o no al hundimiento del Titanic, basÃ¡ndonos en sus caracterÃ­sticas personales como clase, sexo, edad, nÃºmero de familiares, tarifa pagada, entre otros.

Para esto, utilizamos tres modelos de clasificaciÃ³n muy populares:
- RegresiÃ³n LogÃ­stica
- Ãrbol de DecisiÃ³n
- Random Forest

Luego de entrenarlos, comparamos su desempeÃ±o mediante mÃ©tricas como accuracy, precision, recall y F1-score, y visualizamos sus resultados a travÃ©s de grÃ¡ficos y matrices de confusiÃ³n.

i. **Resultados Generales de PrecisiÃ³n**
<br>Al evaluar la precisiÃ³n general de cada modelo, encontramos lo siguiente:
````
    RegresiÃ³n LogÃ­stica: 81.01%
    Random Forest: 79.89%
    Ãrbol de DecisiÃ³n: 78.77%
````

ii. **DistribuciÃ³n de Probabilidades â€“ RegresiÃ³n LogÃ­stica**
<br>Este grÃ¡fico nos ayuda a entender cÃ³mo el modelo de regresiÃ³n logÃ­stica calcula la probabilidad de supervivencia para cada pasajero. Como se observa, hay una clara separaciÃ³n en las predicciones: muchas personas tienen probabilidades muy bajas o muy altas, lo cual indica que el modelo estÃ¡ bastante seguro en la mayorÃ­a de sus decisiones.

La lÃ­nea roja marca el umbral de decisiÃ³n del modelo (0.5), que separa a los que fueron clasificados como sobrevivientes y no sobrevivientes.

iii. **Matrices de ConfusiÃ³n**
<br>Las siguientes grÃ¡ficas muestran cuÃ¡ntas predicciones fueron correctas o incorrectas para cada modelo. Esto permite identificar quÃ© tan bien aciertan en ambas clases (sobrevivientes y no sobrevivientes):
- **RegresiÃ³n LogÃ­stica**
  - Predijo correctamente a 90 personas que no sobrevivieron.
  - Predijo correctamente a 55 personas que sÃ­ sobrevivieron.
  - Se equivocÃ³ con 15 personas (falsos positivos) y con 19 (falsos negativos).
- **Ãrbol de DecisiÃ³n**
    <br>Tuvo mÃ¡s errores que la regresiÃ³n logÃ­stica, especialmente clasificando a personas que no sobrevivieron.
- **Random Forest**
    <br>Su rendimiento fue intermedio entre los dos modelos anteriores, con un nÃºmero de aciertos y errores muy balanceado.

En general, la regresiÃ³n logÃ­stica mostrÃ³ el mejor equilibrio entre precisiÃ³n y sensibilidad (F1-score), lo cual la convierte en una buena opciÃ³n cuando se busca un balance entre ambos aspectos.

### Evidencias
- [Notebook 3](./03_Machine_Learning_Basico/03_Machine_Learning_Basico.ipynb)
- <img src="./03_Machine_Learning_Basico/images/confusion_matrix_decision_tree.png" alt="confusion_matrix_decision_tree.png" width="300"/>
- <img src="./03_Machine_Learning_Basico/images/proba_distribution.png" alt="proba_distribution.png" width="300"/>
- [Ver todas las imÃ¡genes](./03_Machine_Learning_Basico/images/)

### Conclusiones
- La RegresiÃ³n LogÃ­stica se posicionÃ³ como el mejor modelo en este caso, con el mayor puntaje de precisiÃ³n y un buen balance general.
- Random Forest tambiÃ©n mostrÃ³ resultados sÃ³lidos, especialmente en tÃ©rminos de precisiÃ³n.
- Aunque el Ãrbol de DecisiÃ³n fue el mÃ¡s simple, tuvo una leve desventaja frente a los otros modelos.

-------

###  04_Deep_Learning_Intro

##  Acceso directo al notebook
- [Notebook 4 - Deep Learning](./04_Deep_Learning_Intro/04_Deep_Learning_Intro.ipynb)

##  DescripciÃ³n general

Este notebook implementa una red neuronal multicapa utilizando TensorFlow y Keras para resolver un problema de clasificaciÃ³n multiclase basado en el dataset Iris. A travÃ©s de este laboratorio se aborda el flujo completo de un modelo de Deep Learning desde el preprocesamiento hasta la evaluaciÃ³n con grÃ¡ficas y mÃ©tricas.

---

##  Componentes clave del notebook

- ğŸ”¹ Carga del dataset Iris y normalizaciÃ³n con `StandardScaler`
- ğŸ”¹ CodificaciÃ³n `one-hot` para etiquetas multiclase
- ğŸ”¹ Arquitectura de red neuronal secuencial con dos capas ocultas
- ğŸ”¹ CompilaciÃ³n y entrenamiento del modelo
- ğŸ”¹ VisualizaciÃ³n de mÃ©tricas con Matplotlib
- ğŸ”¹ EvaluaciÃ³n con accuracy, loss, matriz de confusiÃ³n y ejemplos visuales

---

###  Resultados del entrenamiento

**PrecisiÃ³n (Accuracy)**

El siguiente grÃ¡fico muestra la evoluciÃ³n de la precisiÃ³n durante las 30 Ã©pocas:

![PrecisiÃ³n del modelo](https://github.com/steven-sanchez-uees/UEES-IA-Semana1-Grupo2/blob/main/04_Deep_Learning_Intro/images/accuracy_plot.png?raw=true)

**InterpretaciÃ³n**:
- Se observa un crecimiento constante de la precisiÃ³n en entrenamiento.
- La validaciÃ³n alcanza aproximadamente un **95%**, lo cual indica buena generalizaciÃ³n sin sobreajuste.

---

**PÃ©rdida (Loss)**

Este grÃ¡fico representa la pÃ©rdida del modelo durante el entrenamiento:

![PÃ©rdida del modelo](https://github.com/steven-sanchez-uees/UEES-IA-Semana1-Grupo2/blob/main/04_Deep_Learning_Intro/images/loss_plot.png?raw=true)

ğŸ“‰ **InterpretaciÃ³n**:
- La pÃ©rdida en validaciÃ³n disminuye progresivamente hasta estabilizarse.
- El modelo logra minimizar el error de forma eficiente, convergiendo correctamente.

---

## ğŸ“Š EvaluaciÃ³n del modelo

### ğŸ”¹ Matriz de ConfusiÃ³n

Representa la relaciÃ³n entre clases verdaderas y predichas:

![Matriz de ConfusiÃ³n](https://github.com/steven-sanchez-uees/UEES-IA-Semana1-Grupo2/blob/main/04_Deep_Learning_Intro/images/confusion_matrix.png?raw=true)

ğŸ“Œ **InterpretaciÃ³n**:
- La diagonal indica predicciones correctas.
- Una alta concentraciÃ³n en la diagonal muestra un modelo eficaz.

---

### ğŸ”¹ Predicciones aleatorias

Ejemplos visuales de predicciones en imÃ¡genes de prueba:

![Predicciones aleatorias](https://github.com/steven-sanchez-uees/UEES-IA-Semana1-Grupo2/blob/main/04_Deep_Learning_Intro/images/predicciones_random.png?raw=true)

ğŸ“Œ **InterpretaciÃ³n**:
- Muestra imÃ¡genes clasificadas correctamente por el modelo.
- Se comparan etiquetas verdaderas (`V`) con predicciones (`P`).

---

### ğŸ“ MÃ©tricas finales del modelo

| MÃ©trica     | Valor aproximado |
|-------------|------------------|
| Accuracy    | ~0.99            |
| MSE         | *0.03 (ejemplo)* |
| MAE         | *0.02 (ejemplo)* |
| RÂ² Score    | *0.95 (ejemplo)* |

ğŸ“Œ **Notas**:
- **Accuracy** indica precisiÃ³n general del modelo.
- **MSE / MAE** miden el error cuadrÃ¡tico y absoluto.
- **RÂ²** evalÃºa quÃ© tan bien se ajustan las predicciones a los valores reales.

---

## ğŸ§  ConclusiÃ³n general

El modelo desarrollado demostrÃ³ un desempeÃ±o sobresaliente en la clasificaciÃ³n del dataset Iris. Tanto las mÃ©tricas como las grÃ¡ficas evidencian un entrenamiento exitoso, con buena capacidad de generalizaciÃ³n, sin indicios significativos de sobreajuste. Las visualizaciones refuerzan la confianza en las predicciones del modelo.

---





-------
> *Desarrollado por el Grupo 2 â€“ Universidad EspÃ­ritu Santo (UEES)*
> 
> â€¢ Steven SÃ¡nchez [@steven-sanchez-uees](https://github.com/steven-sanchez-uees)<br>
> â€¢ Joel EspÃ­n [@joel-espin-uees](https://github.com/joel-espin-uees)<br>
> â€¢ Cristina Gramal [@cristina-gramal](https://github.com/cristina-gramal)<br>
> â€¢ Veronica Ochoa [@veritochoah](https://github.com/veritochoah)<br>
> â€¢ DarÃ­o PÃ©rez [@dario-perez-v](https://github.com/dario-perez-v)<br>
> â€¢ Tomas Guijo [@tguijo](https://github.com/tguijo)<br>

